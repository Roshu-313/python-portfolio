# ğŸ¤– Agent Backend API (Project 5)

A production-style **agentic AI backend service** built with FastAPI.  
This project exposes an intelligent, tool-using agent as a **reliable JSON API**, following real-world backend architecture principles.

---

## ğŸ“Œ Project Purpose

The goal of this project is to convert a locally running AI agent into a **backend service** that:

- Can be consumed by any frontend or external system
- Accepts structured JSON input
- Returns structured JSON output
- Remains stable even when the agent fails

This mirrors how modern AI systems (ChatGPT, Gemini, Claude, Copilot) are deployed in production.

---

## ğŸ§  What This Agent Can Do

- Accept natural language tasks via an API
- Decide whether to use tools (AI-based + rule-based fallback)
- Perform math calculations using a calculator tool
- Maintain short-term memory of interactions
- Safely handle errors without crashing the server

---

## ğŸ—ï¸ Architecture Overview

Client (Browser / App / API)
â†“
FastAPI (API Layer)
â†“
Agent Executor
â†“
Tool Selection (AI + Rules)
â†“
Tool Execution (Calculator)


Key design principle:
> **Agents can fail, APIs must not.**

---

## ğŸ§© Key Concepts Used

- Agent executor pattern
- Tool selection (AI + fallback rules)
- Separation of concerns (API vs agent logic)
- Safe execution boundaries
- JSON request/response contracts
- Memory storage (in-process)

---

## ğŸ“ Project Structure

agent-backend-api/
â”‚
â”œâ”€â”€ main.py # FastAPI app (API layer)
â”œâ”€â”€ agent.py # Agent logic (reasoning, tools, memory)
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md


---

## âš™ï¸ Technologies Used

- Python 3
- FastAPI
- Uvicorn
- Hugging Face Inference API
- Requests
- Pydantic

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Install Dependencies

```bash
python -m pip install -r requirements.txt
2ï¸âƒ£ Set Hugging Face Token (Optional but Recommended)
Create a free token at: https://huggingface.co/settings/tokens

Then set it as an environment variable:

Windows (PowerShell):

setx HF_TOKEN "your_token_here"
macOS / Linux:

export HF_TOKEN="your_token_here"
3ï¸âƒ£ Start the API Server
python -m uvicorn main:app --reload
4ï¸âƒ£ Test the API
Open your browser at:

http://127.0.0.1:8000/docs
Use the POST /agent endpoint with JSON input:

{
  "task": "what is 100 divided by 4"
}
Example response:

{
  "result": "Result: 25"
}
ğŸ§ª CLI Mode (Optional)
The agent can also be run directly in the terminal:

python agent.py
This is useful for local testing and debugging.

ğŸ›¡ï¸ Reliability & Safety
Agent errors do not crash the API

All failures return controlled JSON responses

Clear separation between:

API layer

Agent logic

Tool execution

This makes the system deployable and extensible.

ğŸš€ Whatâ€™s Next
This project is part of a larger roadmap toward advanced agentic AI systems.

Upcoming projects include:

RAG-based agents (document knowledge)

Multi-tool intelligent agents

Multi-agent coordination

Full-stack agentic AI systems

Product-level AI applications

ğŸ‘¤ Author
Roshan Faisal
BSCS Student | Agentic AI & Generative AI Developer
Focused on building real-world AI systems, not demos.
